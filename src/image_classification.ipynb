{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPool2D, Dense, BatchNormalization, GlobalAveragePooling2D, ReLU, RandomFlip, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay, classification_report\n",
    "\n",
    "from dotenv import load_dotenv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LoadData:\n",
    "  \"\"\"\n",
    "  LoadData class\n",
    "  \"\"\"\n",
    "\n",
    "  def __init__(self, base_path):\n",
    "    \"\"\"\n",
    "    Default constructor.\n",
    "    \"\"\"\n",
    "    self.base_path = base_path\n",
    "\n",
    "  def load_data(self):\n",
    "    \"\"\"\n",
    "    Purpose:\n",
    "      Loads the paths of all of the images, and create a one hot encoding for \n",
    "      their classifications. x and y lists share an index relation.\n",
    "    Args:\n",
    "      self - class instance.\n",
    "    Returns:\n",
    "      x - list of image paths.\n",
    "      y - list of one hot encodings of each image's classification.\n",
    "    \"\"\"\n",
    "    x = []\n",
    "    y = []\n",
    "    # Loop through each directory.\n",
    "    for class_number in range(10):\n",
    "      class_number_str = 'c' + str(class_number)\n",
    "      # Path to all images in current class directory.\n",
    "      path = os.path.join(self.base_path, 'imgs/data', class_number_str, '*.jpg')\n",
    "      # Gets all file names matching given path.\n",
    "      file_paths = glob.glob(path)\n",
    "      sub_x = []\n",
    "      sub_y = []\n",
    "      # Loops through each path in the current class directory.\n",
    "      for file_path in file_paths:\n",
    "          sub_x.append(file_path)\n",
    "          # Create one hot encoding.\n",
    "          temp = np.zeros(10)\n",
    "          temp[class_number] = 1\n",
    "          sub_y.append(temp)\n",
    "      # Shuffle the paths.\n",
    "      self.shuffle_data(sub_x)\n",
    "      x.append(sub_x)\n",
    "      y.append(sub_y)\n",
    "    print(\"Saved all image paths.\")\n",
    "    return x, y\n",
    "\n",
    "  def shuffle_data(self, x):\n",
    "    \"\"\"\n",
    "    Purpose:\n",
    "      Shuffles the values of the given array.\n",
    "    Args:\n",
    "      self - class instance.\n",
    "      x - the array to shuffle.\n",
    "    \"\"\"\n",
    "    np.random.shuffle(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "HEIGHT = 256\n",
    "WIDTH = 256\n",
    "\n",
    "load_dotenv()\n",
    "PATH = os.getenv('PATH_TO_DATA')\n",
    "x, y = LoadData(PATH).load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PreProcessing:\n",
    "  \"\"\"\n",
    "  PreProcessing class.\n",
    "  \"\"\"\n",
    "\n",
    "  def __init__(self):\n",
    "    \"\"\"\n",
    "    Default constructor.\n",
    "    \"\"\"\n",
    "    self.kernel = np.array([[-1, -1, -1],\n",
    "                  [-1, 8,-1],\n",
    "                  [-1, -1, -1]])\n",
    "  \n",
    "  def get_colour_type(self, img_path):\n",
    "    \"\"\"\n",
    "    Purpose:\n",
    "      Gets the colour type of the given image.\n",
    "    Args:\n",
    "      self - class instance.\n",
    "      img_path - the path of the image to check the colour type of.\n",
    "    Returns:\n",
    "      The number of channels the image has. 3 for RBG/HSV and 1 for grayscale.\n",
    "    \"\"\"\n",
    "    image = cv2.imread(img_path)\n",
    "    if len(image.shape) == 3: return 3\n",
    "    return 1\n",
    "\n",
    "  def preprocess_image(self, img_path, height, width, training):\n",
    "    \"\"\"\n",
    "    Purpose:\n",
    "      Takes image path, reads it and applies image processing to it.\n",
    "      Threshold grayscale image, sharpen a copy of the base image,\n",
    "      add the results to get the final image, and resize the image \n",
    "      to the specified height and width. If training is true,\n",
    "      image will have random erasing applied to it.\n",
    "    Args:\n",
    "      self - class instance.\n",
    "      img_path - the path to the image.\n",
    "      height - the height of the final image.\n",
    "      width - the width of the final image.\n",
    "      training - the training flag.\n",
    "    Returns:\n",
    "      Preprocessed image of type ndarray.\n",
    "    \"\"\"\n",
    "\n",
    "    color_type = self.get_colour_type(img_path)\n",
    "    # Image is in grayscale.\n",
    "    if color_type == 1:\n",
    "      img = cv2.imread(img_path, 0)\n",
    "      # Apply adaptive thresholding.\n",
    "      img_gray = cv2.threshold(img,0,255,cv2.THRESH_TRUNC+cv2.THRESH_OTSU) \n",
    "      # Sharpen image using lapacian filter.\n",
    "      image_sharp = cv2.filter2D(src=img, ddepth=-1, kernel=self.kernel)\n",
    "\n",
    "    # Image is in BGR/HSV\n",
    "    elif color_type == 3:\n",
    "      img = cv2.imread(img_path)\n",
    "      # Convert to grayscale.\n",
    "      img_gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "      # Apply adaptive thresholding.\n",
    "      img_gray = cv2.threshold(img_gray,0,255,cv2.THRESH_TRUNC+cv2.THRESH_OTSU)\n",
    "      # Sharpen image using laplacian filter.\n",
    "      image_sharp = cv2.filter2D(src=img, ddepth=-1, kernel=self.kernel)\n",
    "      # Convert sharpened image to grayscale.\n",
    "      image_sharp = cv2.cvtColor(image_sharp, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    # Combine thresholded image and sharpened image.\n",
    "    combined = cv2.add(image_sharp, img_gray[1])\n",
    "    # Resize image.\n",
    "    dst = cv2.resize(combined, (width, height))\n",
    "    # Convert to BGR.\n",
    "    img = cv2.cvtColor(dst, cv2.COLOR_GRAY2BGR)\n",
    "    # Checks if image is apart of training set.\n",
    "    if training:\n",
    "      # Apply random erasing to processed image.\n",
    "      img = self.random_erasing(img)\n",
    "    return img\n",
    "\n",
    "  def random_erasing(self, image, probability=0.5, sl = 0.02, sh = 0.4, r1 = 0.3, mean=[0.4914, 0.4822, 0.4465]):\n",
    "    \"\"\"\n",
    "    Function that performs Random Erasing in Random Erasing Data Augmentation by Zhong et al. \n",
    "    -------------------------------------------------------------------------------------\n",
    "    probability: The probability that the operation will be performed.\n",
    "    sl: min erasing area\n",
    "    sh: max erasing area\n",
    "    r1: min aspect ratio\n",
    "    mean: erasing value\n",
    "    ------\n",
    "    Source: https://github.com/zhunzhong07/Random-Erasing/blob/master/transforms.py\n",
    "    \"\"\"\n",
    "    if np.random.uniform(0, 1) > probability:\n",
    "        return image\n",
    "    area = image.shape[0] * image.shape[1]\n",
    "    for _ in range(100):\n",
    "        target_area = np.random.uniform(sl, sh) * area\n",
    "        aspect_ratio = np.random.uniform(r1, 1/r1)\n",
    "\n",
    "        h = int(round(np.sqrt(target_area * aspect_ratio)))\n",
    "        w = int(round(np.sqrt(target_area / aspect_ratio)))\n",
    "\n",
    "        if w < image.shape[1] and h < image.shape[0]:\n",
    "            x1 = np.random.randint(0, image.shape[0] - h)\n",
    "            y1 = np.random.randint(0, image.shape[1] - w)\n",
    "            if image.shape[2] == 3:\n",
    "                image[x1:x1+h, y1:y1+w, 0] = mean[0]\n",
    "                image[x1:x1+h, y1:y1+w, 1] = mean[1]\n",
    "                image[x1:x1+h, y1:y1+w, 2] = mean[2]\n",
    "            else:\n",
    "                image[x1:x1+h, y1:y1+w, 0] = mean[0]\n",
    "            return image\n",
    "    return image\n",
    "  \n",
    "  def split_data(self, x, y, height, width):\n",
    "    \"\"\"\n",
    "    Purpose:\n",
    "      Split the data into test and train, and process the images.\n",
    "    Args:\n",
    "      self - class instance.\n",
    "      x - the paths of all of the images.\n",
    "      y - the classifications, related to x by index.\n",
    "      height - the height of the image used in resizing.\n",
    "      width - the width of the image used in resizing.\n",
    "    Returns:\n",
    "      ndarrays of x and y train and test sets.\n",
    "    \"\"\"\n",
    "    x_train = []\n",
    "    y_train = []\n",
    "    x_test = []\n",
    "    y_test = []\n",
    "    # Get the split points of each class.\n",
    "    split_points = self.percent_indexes(x)\n",
    "    # Loop through all classes\n",
    "    for class_num, (xi, yi) in enumerate(zip(x, y)):\n",
    "      print(f\"Preprocessing class: {class_num}.\")\n",
    "      # Loop through each image in the class.\n",
    "      for image_number, (image_path, out) in enumerate(zip(xi, yi)):\n",
    "        # Check if its less than the split point.\n",
    "        if image_number < split_points[class_num]:\n",
    "          # Process the image with training flag set to false, add it to the x_test\n",
    "          # list along with the one hot encoding classification for the image.\n",
    "          image = self.preprocess_image(image_path, height, width, False)\n",
    "          x_test.append(image)\n",
    "          y_test.append(out)\n",
    "        else:\n",
    "          # Process the image with training flag set to True, add it to the x_train\n",
    "          # list along with the one hot encoding classification for the image.\n",
    "          image = self.preprocess_image(image_path, height, width, True)\n",
    "          x_train.append(image)\n",
    "          y_train.append(out)\n",
    "    return np.array(x_train), np.array(y_train), np.array(x_test), np.array(y_test)\n",
    "  \n",
    "  def percent_indexes(self, x):\n",
    "    \"\"\"\n",
    "    Purpose:\n",
    "      Used to get the points of where the x_test and x_train will be split.\n",
    "      Split point is 20% of the number of images in each class.\n",
    "    Args:\n",
    "      self - class instance.\n",
    "      x - the paths of all of the images.\n",
    "    Returns:\n",
    "      Returns a list of 10 index points to split each class.\n",
    "    \"\"\"\n",
    "    split_points = []\n",
    "    for xi in x:\n",
    "      number_of_images = len(xi)\n",
    "      split_point = int(number_of_images*0.2)\n",
    "      split_points.append(split_point)\n",
    "    return split_points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = PreProcessing()\n",
    "x_train, y_train, x_test, y_test = p.split_data(x, y, HEIGHT, WIDTH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VGG16:\n",
    "  \"\"\"\n",
    "  VGG16 model class.\n",
    "  \"\"\"\n",
    "\n",
    "  def __init__(self, input_shape=(None, None, None, 3)):\n",
    "    \"\"\"\n",
    "    Default constructor.\n",
    "    \"\"\"\n",
    "    self.model = self.create_model(input_shape)\n",
    "    self.model.summary()\n",
    "\n",
    "  def create_model(self, input_shape):\n",
    "    \"\"\"\n",
    "    Purpose:\n",
    "      Creates the VGG16 model.\n",
    "    Args:\n",
    "      self - class instance.\n",
    "      input_shape - the shape of the input into the model. \n",
    "                    (BATCH SIZE, HEIGHT, WIDTH, NUMBER OF CHANNELs)\n",
    "    Returns:\n",
    "      The compiled tensorflow model.\n",
    "    \"\"\"\n",
    "    # Data augmentation.\n",
    "    data_aug = Sequential([RandomFlip(\"horizontal\")])\n",
    "\n",
    "    # Model.\n",
    "    model = Sequential([\n",
    "      # Data augmentation layer.\n",
    "      data_aug,\n",
    "\n",
    "      # First Convolutional Block.\n",
    "      Conv2D(32, (3, 3), padding='same'),\n",
    "      BatchNormalization(),\n",
    "      ReLU(),\n",
    "      MaxPool2D((1, 1), strides=(1, 1)),\n",
    "      Conv2D(32, (3, 3), padding='same'),\n",
    "      BatchNormalization(axis=3),\n",
    "      ReLU(),\n",
    "      MaxPool2D((2, 2), strides=(2, 2)),\n",
    "\n",
    "      # Second Convolutional Block.\n",
    "      Conv2D(64, (3, 3), padding='same'),\n",
    "      BatchNormalization(),\n",
    "      ReLU(),\n",
    "      MaxPool2D((1, 1), strides=(1, 1)),\n",
    "      Conv2D(64, (3, 3), padding='same'),\n",
    "      BatchNormalization(axis=3),\n",
    "      ReLU(),\n",
    "      MaxPool2D((2, 2), strides=(2, 2)),\n",
    "\n",
    "      # Third Convolutional Block.\n",
    "      Conv2D(128, (3, 3), padding='same'),\n",
    "      BatchNormalization(),\n",
    "      ReLU(),\n",
    "      MaxPool2D((1, 1), strides=(1, 1)),\n",
    "      Conv2D(128, (3, 3), padding='same'),\n",
    "      BatchNormalization(),\n",
    "      ReLU(),\n",
    "      MaxPool2D((1, 1), strides=(1, 1)),\n",
    "      Conv2D(128, (3, 3), padding='same'),\n",
    "      BatchNormalization(axis=3),\n",
    "      ReLU(),\n",
    "      MaxPool2D((2, 2), strides=(2, 2)),\n",
    "\n",
    "      # Fourth Convolutional Block.\n",
    "      Conv2D(256, (3, 3), padding='same'),\n",
    "      BatchNormalization(),\n",
    "      ReLU(),\n",
    "      MaxPool2D((1, 1), strides=(1, 1)),\n",
    "      Conv2D(256, (3, 3), padding='same'),\n",
    "      BatchNormalization(),\n",
    "      ReLU(),\n",
    "      MaxPool2D((1, 1), strides=(1, 1)),\n",
    "      Conv2D(256, (3, 3), padding='same'),\n",
    "      BatchNormalization(axis=3),\n",
    "      ReLU(),\n",
    "      MaxPool2D((2, 2), strides=(2, 2)),\n",
    "\n",
    "      # Fifth Convolutional Block.\n",
    "      Conv2D(256, (3, 3), padding='same'),\n",
    "      BatchNormalization(),\n",
    "      ReLU(),\n",
    "      MaxPool2D((1, 1), strides=(1, 1)),\n",
    "      Conv2D(256, (3, 3), padding='same'),\n",
    "      BatchNormalization(),\n",
    "      ReLU(),\n",
    "      MaxPool2D((1, 1), strides=(1, 1)),\n",
    "      Conv2D(256, (3, 3), padding='same'),\n",
    "      BatchNormalization(axis=3),\n",
    "      ReLU(),\n",
    "      MaxPool2D((2, 2), strides=(2, 2)),\n",
    "\n",
    "      # Fully Connected Layers.\n",
    "      GlobalAveragePooling2D(),\n",
    "      Dense(1024, activation='relu'),\n",
    "      Dropout(0.5),\n",
    "      Dense(10, activation='softmax')\n",
    "    ])\n",
    "    # Build the model with the provided input shape.\n",
    "    model.build(input_shape=input_shape)\n",
    "    # Compile the model with adam optimizer and categorical crossentropy.\n",
    "    model.compile(optimizer=Adam(), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "  def fit_model(self, x_train, y_train, epochs, batch_size, verbose):\n",
    "    \"\"\"\n",
    "    Purpose:\n",
    "      Fits the model with the training data sets.\n",
    "    Args:\n",
    "      self - class instance.\n",
    "      x_train - the input training data set.\n",
    "      y_train - the output training data set.\n",
    "      epochs - the number of epochs to train the model.\n",
    "      batch_size - the batch size to use in training.\n",
    "      verbose - the verbose flag to use to display the training progress.\n",
    "    Returns:\n",
    "      None\n",
    "    \"\"\"\n",
    "    self.model.fit(x_train, y_train, epochs=epochs, verbose=verbose, batch_size=batch_size)\n",
    "    \n",
    "  def evaluate_model(self, x_test, y_test):\n",
    "    \"\"\"\n",
    "    Purpose:\n",
    "      Evaluates the model with the test data set.\n",
    "    Args:\n",
    "      self - class instance.\n",
    "      x_test - the input test data set.\n",
    "      y_test - the output test data set.\n",
    "    Returns:\n",
    "      None\n",
    "    \"\"\"\n",
    "    test_loss, test_acc = self.model.evaluate(x_test, y_test)\n",
    "    print(f\"Test lost: {test_loss} -- Test accuracy: {test_acc}\")\n",
    "\n",
    "  def predict_model(self, x_test, y_test, batch_size, verbose):\n",
    "    \"\"\"\n",
    "    Purpose:\n",
    "      Predict the output of the model with the input test set.\n",
    "    Args:\n",
    "      self - class instance.\n",
    "      x_test - the input test data set.\n",
    "      y_test - the output test data set.\n",
    "      verbose - the verbose flag to use to display the predicting progress.\n",
    "    Returns:\n",
    "      None\n",
    "    \"\"\"\n",
    "    y_pred = self.model.predict(x_test, batch_size=batch_size, verbose=verbose)\n",
    "    # Display confusion matrix and accuracy of predicted values.\n",
    "    self.display_prediction_results(y_pred, y_test)\n",
    "\n",
    "  def display_prediction_results(self, y_pred, y_test):\n",
    "    \"\"\"\n",
    "    Purpose:\n",
    "      Displays the confusion matrix and the models accuracy, recall, precision and F1 score.\n",
    "    Args:\n",
    "      self - class instance.\n",
    "      y_pred - the predicted outputs.\n",
    "      y_test - the actual outputs.\n",
    "    Returns:\n",
    "      None\n",
    "    \"\"\"\n",
    "    # Get the index of the max value in each sub array.\n",
    "    y_pred = np.argmax(y_pred, axis=1)\n",
    "    y_test = np.argmax(y_test, axis=1)\n",
    "    # Names of possible classes.\n",
    "    class_names = ['c0','c1','c2','c3','c4','c5','c6','c7','c8','c9']\n",
    "    # Generate confusion matrix.\n",
    "    conf_mat = confusion_matrix(y_test, y_pred)\n",
    "    display = ConfusionMatrixDisplay(confusion_matrix=conf_mat, display_labels=class_names)\n",
    "    # Increases the size of the displayed confusion matrix\n",
    "    fig, ax = plt.subplots(figsize=(10,10))\n",
    "    # Plot the confusion matrix.\n",
    "    display.plot(ax=ax, values_format='')\n",
    "    # Output the models accuracy, recall, precision and F1 score.\n",
    "    print(classification_report(y_test, y_pred, target_names=class_names))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 15\n",
    "VERBOSE = 1\n",
    "BATCH_SIZE = 16\n",
    "\n",
    "\n",
    "model = VGG16((None, HEIGHT, WIDTH, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit_model(x_train, y_train, EPOCHS, BATCH_SIZE, VERBOSE)\n",
    "model.evaluate_model(x_test, y_test)\n",
    "model.predict_model(x_test, y_test, BATCH_SIZE, VERBOSE)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
